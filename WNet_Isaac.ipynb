{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from glob import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import src.wnet as wnet\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Dataset\n",
    "class BSDS500_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, subset):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_paths = glob(os.path.join(root_dir, 'BSDS500', 'data', 'images', subset, '*.jpg'))\n",
    "        self.image_sizes = [np.take(torchvision.io.read_image(img_path).shape, [1,2]) for img_path in self.image_paths]\n",
    "        self.image_size = (224, 224)\n",
    "        \n",
    "        self.max_image = None\n",
    "        self.min_image = None\n",
    "        for i in range(self.__len__()):\n",
    "            image = torchvision.io.read_image(self.image_paths[i]).float()\n",
    "            image = torchvision.transforms.functional.resize(image, self.image_size, interpolation=torchvision.transforms.functional.InterpolationMode.BILINEAR)\n",
    "            self.max_image = torch.max(self.max_image, image) if self.max_image is not None else image\n",
    "            self.min_image = torch.min(self.min_image, image) if self.min_image is not None else image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def size(self, idx=None):\n",
    "        s = [self.__len__(), 3, self.image_size[0], self.image_size[1]]\n",
    "        if idx is not None:\n",
    "            s = s[idx]\n",
    "        else:\n",
    "            s = torch.Size(s)\n",
    "        return s\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = torchvision.io.read_image(img_path)\n",
    "        image = image.float()\n",
    "        image = torchvision.transforms.functional.resize(image, self.image_size, interpolation=torchvision.transforms.functional.InterpolationMode.BILINEAR)\n",
    "        image = (image - self.min_image) / (self.max_image - self.min_image)\n",
    "        return image.to(device)\n",
    "\n",
    "class BSDS500():\n",
    "    def __init__(self, root_dir, batch_size):\n",
    "        self.trainset = BSDS500_dataset(root_dir, 'train')\n",
    "        self.trainloader = torch.utils.data.DataLoader(self.trainset, batch_size=batch_size, shuffle=True)\n",
    "        self.valset = BSDS500_dataset(root_dir, 'val')\n",
    "        self.valloader = torch.utils.data.DataLoader(self.valset, batch_size=batch_size, shuffle=False)\n",
    "        self.testset = BSDS500_dataset(root_dir, 'test')\n",
    "        self.testloader = torch.utils.data.DataLoader(self.testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    def get_trainloader(self):\n",
    "        return self.trainloader\n",
    "    \n",
    "    def get_valloader(self):\n",
    "        return self.valloader\n",
    "\n",
    "    def get_testloader(self):\n",
    "        return self.testloader\n",
    "\n",
    "if device == \"mps\":\n",
    "    batch_size = 16\n",
    "else:\n",
    "    batch_size = 8\n",
    "\n",
    "dataset = BSDS500('../BSDS500', batch_size)\n",
    "X_train = dataset.get_trainloader()\n",
    "y_train = dataset.get_trainloader()\n",
    "X_val = dataset.get_valloader()\n",
    "y_val = dataset.get_valloader()\n",
    "X_test = dataset.get_testloader()\n",
    "y_test = dataset.get_testloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from models/wnet-2022-12-02-02-50.pt\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import src.wnet as wnet\n",
    "import src.network as network\n",
    "import src.loss as loss\n",
    "loss = reload(loss)\n",
    "network = reload(network)\n",
    "wnet = reload(wnet)\n",
    "\n",
    "train = False\n",
    "epochs = 500\n",
    "use_checkpoint = True\n",
    "checkpoint_path = 'models/wnet-2022-12-02-02-50.pt'\n",
    "\n",
    "net = wnet.WNet(device_type=device)\n",
    "net.to(device)\n",
    "if use_checkpoint:\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    net.to(device)\n",
    "    print('Loaded checkpoint from {}'.format(checkpoint_path))\n",
    "\n",
    "if train:\n",
    "    net.fit(\n",
    "        X_train, y_train,\n",
    "        X_val, y_val,\n",
    "        epochs=epochs,\n",
    "        learn_rate=1e-3,\n",
    "        weight_decay=1e-5\n",
    "    )\n",
    "    date = datetime.now().__str__()\n",
    "    date = date[:16].replace(':', '-').replace(' ', '-')\n",
    "    torch.save({\n",
    "                'epoch': epochs,\n",
    "                'model_state_dict': net.state_dict(),\n",
    "                }, f'models/wnet-{date}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [08:02, 19.30s/it]\n"
     ]
    }
   ],
   "source": [
    "import utils.visualize as visualize\n",
    "from src.crf import crf_fit_predict, crf_batch_fit_predict\n",
    "import tqdm\n",
    "\n",
    "all_inputs = []\n",
    "all_masks = []\n",
    "all_network_masks = []\n",
    "for i,batch in tqdm.tqdm(enumerate(X_test)):\n",
    "  inputs = batch\n",
    "  mask, outputs = net.forward(inputs)\n",
    "  inputs = inputs.detach().cpu().numpy()\n",
    "  outputs = outputs.detach().cpu().numpy()\n",
    "  mask = mask.detach().cpu().numpy()\n",
    "  crf_mask = crf_batch_fit_predict(mask, inputs)\n",
    "  for j in range(inputs.shape[0]):\n",
    "    all_inputs.append(inputs[j])\n",
    "    all_network_masks.append(mask[j])\n",
    "    all_masks.append(crf_mask[j])\n",
    "    \n",
    "all_masks = np.array(all_masks)\n",
    "all_inputs = np.array(all_inputs)\n",
    "all_network_masks = np.array(all_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert segmentation mask to RGB with colors averaged from the image\n",
    "def mask_to_rgb(mask, image):\n",
    "    mask = mask.argmax(0)\n",
    "    image = image.transpose(1,2,0)\n",
    "    mask_rgb = np.zeros(image.shape)\n",
    "    for i in range(1, mask.max()+1):\n",
    "        mask_rgb[mask==i] = image[mask==i].mean(0)\n",
    "    return mask_rgb\n",
    "\n",
    "# edge detection using sobel filter\n",
    "def sobel_edge_detection(image):\n",
    "    image = skimage.color.rgb2gray(image)\n",
    "    edges = skimage.filters.sobel(image)\n",
    "    return edges\n",
    "\n",
    "# segmentation mask to csv\n",
    "def mask_to_csv(mask):\n",
    "    mask = mask.argmax(0)\n",
    "    print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12573/2182552978.py:10: RuntimeWarning: Mean of empty slice.\n",
      "  mask_rgb[mask==i] = image[mask==i].mean(0)\n",
      "/home/remote/anaconda3/envs/torch/lib/python3.9/site-packages/numpy/core/_methods.py:181: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n"
     ]
    }
   ],
   "source": [
    "for i in range(all_masks.shape[0]):\n",
    "    mask = mask_to_rgb(all_masks[i], all_inputs[i])\n",
    "    mask = torch.from_numpy(mask).permute(2,0,1)\n",
    "    id = dataset.testset.image_paths[i].split(\"/\")[-1].split(\".\")[0]\n",
    "    mask = torchvision.transforms.functional.resize(mask, list(dataset.testset.image_sizes[i]), interpolation=torchvision.transforms.functional.InterpolationMode.NEAREST)\n",
    "    torchvision.utils.save_image(mask, f'outputs/png/{id}.png')\n",
    "    \n",
    "    # mask = mask_to_rgb(all_masks[i], all_inputs[i])\n",
    "    mask = (skimage.color.rgb2gray(mask.permute(1,2,0)) * 255).round()\n",
    "    colors = np.unique(mask)\n",
    "    for i,color in enumerate(colors):\n",
    "        mask[mask==color] = i\n",
    "    np.savetxt(f'outputs/csv/{id}.csv', mask, delimiter=',', fmt='%i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:18<00:00,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (averaged over gt segmentations) mIOU:  0.11433732975607845\n",
      "Max (over gt segmentations) mIOU:  0.2720017964656836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from evaluation import calculate_mIOU\n",
    "\n",
    "average_mIOU, max_mIOU = calculate_mIOU(\"../BSDS500/gt\", \"outputs/csv\")\n",
    "print(\"Average (averaged over gt segmentations) mIOU: \", average_mIOU)\n",
    "print(\"Max (over gt segmentations) mIOU: \", max_mIOU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62c1fc8ce564a981a915002e6920342d4f3cca917e7f319eb81efd20e068d558"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
